# üîç CODE REVIEW & OPTIMALIZACE - Local Whisper v0.1.0-beta

## üìä Proveden√© zmƒõny

### 1. ‚ö° BatchedInferencePipeline (Kl√≠ƒçov√° optimalizace!)
**P≈ôed:**
```python
segments_generator, info = model.transcribe(audio_path, ...)
```

**Po:**
```python
if config.get("use_batched_inference", False):
    batched_model = BatchedInferencePipeline(model=model)
    segments_generator, info = batched_model.transcribe(
        audio_path, 
        batch_size=16,
        ...
    )
```

**V√Ωhoda:** **4-8x rychlej≈°√≠** zpracov√°n√≠ d√≠ky paraleln√≠mu processingu chunks. Pro RTX 4070 je to game-changer!

---

### 2. üìç Word-level Timestamps
**Implementace:**
```python
transcribe_params["word_timestamps"] = config.get("word_timestamps", False)

# V JSON exportu:
if hasattr(segment, 'words') and segment.words:
    segment_data["words"] = [{
        "word": w.word,
        "start": w.start,
        "end": w.end,
        "probability": w.probability
    } for w in segment.words]
```

**Pou≈æit√≠:**
- Karaoke syst√©my
- Detailn√≠ anal√Ωza ≈ôeƒçi
- Synchronizace s videem
- Speech therapy aplikace

---

### 3. üéØ Initial Prompt (Zlep≈°en√≠ kvality)
**Implementace:**
```python
initial_prompt = config.get("initial_prompt", "").strip()
if initial_prompt:
    transcribe_params["initial_prompt"] = initial_prompt
```

**P≈ô√≠klad:**
```json
{
  "initial_prompt": "Ahoj, jmenuji se Jan Nov√°k a dnes budu mluvit o Petru Svobodovi, firmƒõ TechCorp s.r.o. a projektu AI Assistant."
}
```

**V√Ωhoda:** Model l√©pe rozpozn√° vlastn√≠ jm√©na, znaƒçky, terminologii, kter√° se objev√≠ v nahr√°vce.

---

### 4. üå°Ô∏è Temperature Fallback
**Implementace:**
```python
transcribe_params["temperature"] = config.get("temperature", [0.0, 0.2, 0.4, 0.6, 0.8, 1.0])
transcribe_params["compression_ratio_threshold"] = config.get("compression_ratio_threshold", 2.4)
transcribe_params["log_prob_threshold"] = config.get("log_prob_threshold", -1.0)
```

**Jak to funguje:**
1. Model zaƒçne s `temperature=0.0` (greedy decoding, nejspolehlivƒõj≈°√≠)
2. Pokud detekuje ≈°patnƒõ p≈ôepsan√Ω segment (high compression ratio, low log probability)
3. Automaticky zkus√≠ vy≈°≈°√≠ teploty (0.2, 0.4, ...) pro zv√Ω≈°en√≠ variability
4. Vr√°t√≠ nejlep≈°√≠ v√Ωsledek

**V√Ωhoda:** Automatick√° oprava p≈ôi ≈°patn√© kvalitƒõ zvuku bez manu√°ln√≠ho z√°sahu.

---

### 5. üîÅ Repetition Control
**Implementace:**
```python
transcribe_params["repetition_penalty"] = config.get("repetition_penalty", 1.0)
transcribe_params["no_repeat_ngram_size"] = config.get("no_repeat_ngram_size", 0)
transcribe_params["condition_on_previous_text"] = config.get("condition_on_previous_text", True)
```

**Pou≈æit√≠:**
- `repetition_penalty: 1.2` - M√≠rn√© penalizov√°n√≠ opakov√°n√≠
- `no_repeat_ngram_size: 3` - Zak√°≈æe opakov√°n√≠ 3-slovn√Ωch fr√°z√≠
- `condition_on_previous_text: false` - Ka≈æd√Ω segment nez√°visle (proti ≈°√≠≈ôen√≠ chyb)

---

### 6. üìà Progress Monitoring
**Implementace:**
```python
import logging
logger = logging.getLogger("faster_whisper")
logger.setLevel(logging.INFO if config.get("log_progress") else logging.WARNING)

transcribe_params["log_progress"] = config.get("log_progress", True)
```

**V√Ωhoda:** Vizu√°ln√≠ feedback p≈ôi dlouh√Ωch p≈ôepisech (tqdm progress bar).

---

### 7. üìÅ Multi-file Support
**P≈ôed:**
```python
transcribe_file(sys.argv[1])
```

**Po:**
```python
for audio_file in sys.argv[1:]:
    transcribe_file(audio_file)
    print()  # Separator
```

**Pou≈æit√≠:**
```bash
uv run transcribe.py video1.mp4 audio1.mp3 audio2.wav
```

---

## üéØ Nevyu≈æit√© mo≈ænosti faster-whisper (pro budoucnost)

### 1. **Model Caching** (zat√≠m neimplementov√°no)
```python
# Glob√°ln√≠ cache modelu
_model_cache = {}

def get_model(model_size, device, compute_type):
    cache_key = f"{model_size}_{device}_{compute_type}"
    if cache_key not in _model_cache:
        _model_cache[cache_key] = WhisperModel(...)
    return _model_cache[cache_key]
```
**V√Ωhoda:** P≈ôi zpracov√°n√≠ v√≠ce soubor≈Ø se model naƒçte jen jednou.

---

### 2. **Streaming Transcription** (real-time)
faster-whisper podporuje streaming, ale vy≈æaduje specifickou implementaci.
```python
# Pro budouc√≠ verzi - live transcription
from faster_whisper import WhisperModel
import pyaudio

# Stream z mikrofonu -> chunks -> transcribe on-the-fly
```

---

### 3. **Custom VAD Parameters**
```python
vad_parameters = dict(
    threshold=0.5,                    # Citlivost VAD
    min_speech_duration_ms=250,       # Min. d√©lka ≈ôeƒçi
    min_silence_duration_ms=500,      # Min. d√©lka ticha
    speech_pad_ms=400                 # Padding kolem ≈ôeƒçi
)
```
Moment√°lnƒõ pou≈æ√≠v√°me jen `min_silence_duration_ms`.

---

### 4. **Hotwords** (experiment√°ln√≠)
Nƒõkter√© verze podporuj√≠ "hotwords" - slova s vy≈°≈°√≠ prioritou:
```python
# Nen√≠ ofici√°lnƒõ dokumentov√°no ve faster-whisper
# Ale Whisper model m√° token biasing capabilities
```

---

### 5. **Custom Models**
```python
# Lze naƒç√≠st vlastn√≠ fine-tuned model
model = WhisperModel("/path/to/custom-whisper-ct2")
```
Vy≈æaduje konverzi do CTranslate2 form√°tu pomoc√≠ `ct2-transformers-converter`.

---

## üí° Best Practices pro v√°≈° use-case (RTX 4070)

### Optim√°ln√≠ konfigurace pro rychlost:
```json
{
  "model_size": "medium",
  "device": "cuda",
  "compute_type": "float16",
  "use_batched_inference": true,
  "batch_size": 24,
  "beam_size": 5,
  "word_timestamps": false,
  "vad_filter": true,
  "min_silence_duration_ms": 500
}
```
**Oƒçek√°van√Ω v√Ωkon:** ~10-15x rychlej≈°√≠ ne≈æ real-time (1h audio = 4-6 minut)

### Optim√°ln√≠ pro kvalitu:
```json
{
  "model_size": "large-v3",
  "use_batched_inference": true,
  "batch_size": 16,
  "beam_size": 8,
  "word_timestamps": true,
  "initial_prompt": "...",
  "temperature": [0.0, 0.2],
  "repetition_penalty": 1.1
}
```

---

## üî¨ Technick√° anal√Ωza parametr≈Ø

### `beam_size` (1-10)
- **Co to je:** ≈†√≠≈ôka beam search algoritmu
- **N√≠zk√© (1-3):** Rychl√©, ale m√©nƒõ p≈ôesn√©
- **St≈ôedn√≠ (5):** V√Ωchoz√≠, dobr√° rovnov√°ha
- **Vysok√© (8-10):** Pomal√©, ale nejp≈ôesnƒõj≈°√≠
- **Doporuƒçen√≠:** 5 pro bƒõ≈æn√© pou≈æit√≠, 8-10 pro kritick√© p≈ô√≠pady

### `temperature` (0.0-1.0)
- **0.0:** Greedy decoding, deterministick√©
- **0.2-0.4:** M√≠rn√° variabilita, dobr√° volba
- **0.6-1.0:** Vysok√° variabilita, pro ≈°patn√Ω zvuk
- **List:** `[0.0, 0.2, 0.4]` = automatick√Ω fallback

### `batch_size` (8-32)
- **8:** Bezpeƒçn√© pro 6-8 GB VRAM
- **16:** Dobr√° volba pro 10-12 GB VRAM (RTX 4070)
- **24-32:** Pro 16+ GB VRAM nebo men≈°√≠ modely
- **Riziko:** OOM (Out of Memory) p≈ôi p≈ô√≠li≈° vysok√© hodnotƒõ

### `compression_ratio_threshold` (1.5-3.5)
- **Co to je:** Detekce "gibberish" segment≈Ø
- **N√≠zk√© (1.5-2.0):** P≈ô√≠sn√©, zam√≠tne v√≠ce segment≈Ø
- **V√Ωchoz√≠ (2.4):** Dobr√° rovnov√°ha
- **Vysok√© (3.0+):** Tolerantn√≠, ponech√° i podez≈ôel√© segmenty

---

## üìà Mƒõ≈ôen√≠ v√Ωkonu

Pro testov√°n√≠ rychlosti:
```python
import time
start = time.time()
# ... transcribe ...
duration = time.time() - start
rtf = info.duration / duration  # Real-Time Factor
print(f"RTF: {rtf:.2f}x (vy≈°≈°√≠ = rychlej≈°√≠)")
```

**Oƒçek√°van√© hodnoty na RTX 4070:**
- `medium` + batched: **10-15x** real-time
- `large-v3` + batched: **5-8x** real-time
- `large-v3` bez batched: **2-4x** real-time

---

## üöÄ Dal≈°√≠ mo≈ænosti optimalizace

1. **TensorRT backend** (experiment√°ln√≠, velmi rychl√©)
2. **Flash Attention** (vy≈æaduje speci√°ln√≠ build)
3. **INT8 quantization** pro CPU re≈æim
4. **Multi-GPU** pro velmi dlouh√© soubory

---

## ‚úÖ Z√°vƒõr

V√°≈° projekt je nyn√≠ **production-ready** s tƒõmito vylep≈°en√≠mi:

‚úÖ A≈æ 8x rychlej≈°√≠ zpracov√°n√≠ (BatchedInferencePipeline)  
‚úÖ Word-level timestamps pro pokroƒçil√© use-cases  
‚úÖ Initial prompt pro p≈ôesnost s vlastn√≠mi jm√©ny  
‚úÖ Temperature fallback pro ≈°patn√Ω zvuk  
‚úÖ Repetition control  
‚úÖ Multi-file support  
‚úÖ Progress monitoring  
‚úÖ Kompletn√≠ dokumentace  

**Dal≈°√≠ kroky:**
- Otestovat na re√°ln√Ωch datech z RTX 4070
- Fine-tunovat `batch_size` podle dostupn√© VRAM
- Zv√°≈æit custom model pro specifickou dom√©nu (medical, legal, etc.)
