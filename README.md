# ğŸ™ï¸ Local Whisper Transcriber

<div align="center">

![Python](https://img.shields.io/badge/Python-3.12+-blue.svg)
![License](https://img.shields.io/badge/License-MIT-green.svg)
![Whisper](https://img.shields.io/badge/Whisper-faster--whisper-orange.svg)
![GPU](https://img.shields.io/badge/GPU-CUDA%20Ready-brightgreen.svg)

**ExtrÃ©mnÄ› rychlÃ½ lokÃ¡lnÃ­ Speech-to-Text pomocÃ­ faster-whisper**

[Funkce](#-klÃ­ÄovÃ©-vlastnosti) â€¢ [Instalace](#-instalace-na-novÃ©m-poÄÃ­taÄi) â€¢ [PouÅ¾itÃ­](#-pouÅ¾itÃ­) â€¢ [Konfigurace](#%EF%B8%8F-konfigurace-configjson) â€¢ [Dokumentace](#-dalÅ¡Ã­-dokumentace)

</div>

---

JednoduchÃ½, ale **extrÃ©mnÄ› vÃ½konnÃ½** nÃ¡stroj pro **lokÃ¡lnÃ­ pÅ™epis Å™eÄi na text** (Speech-to-Text). VyuÅ¾Ã­vÃ¡ optimalizovanÃ½ engine `faster-whisper` (aÅ¾ 4x rychlejÅ¡Ã­ neÅ¾ originÃ¡lnÃ­ OpenAI Whisper) a bÄ›Å¾Ã­ kompletnÄ› offline na vaÅ¡em poÄÃ­taÄi.

## âœ¨ KlÃ­ÄovÃ© vlastnosti

*   **100% SoukromÃ­:** Å½Ã¡dnÃ¡ data se neposÃ­lajÃ­ do cloudu. VÅ¡e bÄ›Å¾Ã­ u vÃ¡s.
*   **GPU Akcelerace:** PlnÃ¡ podpora pro NVIDIA karty (CUDA) s automatickÃ½m pÅ™epnutÃ­m na CPU, pokud GPU nenÃ­ dostupnÃ©.
*   **Batched Inference:** AÅ¾ **8x rychlejÅ¡Ã­** zpracovÃ¡nÃ­ pomocÃ­ paralelnÃ­ho batch processingu.
*   **Word-level Timestamps:** ÄŒasovÃ© znaÄky pro kaÅ¾dÃ© slovo (karaoke, detailnÃ­ analÃ½za).
*   **Initial Prompt:** ZlepÅ¡enÃ­ pÅ™esnosti pro vlastnÃ­ jmÃ©na a odbornou terminologii.
*   **Temperature Fallback:** AutomatickÃ¡ oprava pÅ™i Å¡patnÃ© kvalitÄ› zvuku.
*   **FormÃ¡ty:** Generuje nejen text (`.txt`), ale i titulky (`.srt`, `.vtt`) a metadata (`.json`).
*   **Detekce Å™eÄi (VAD):** Automaticky filtruje tichÃ¡ mÃ­sta pro pÅ™esnÄ›jÅ¡Ã­ pÅ™epis.
*   **Portable:** DÃ­ky nÃ¡stroji `uv` mÃ¡ projekt izolovanÃ© Python prostÅ™edÃ­.

---

## ğŸš€ Instalace na novÃ©m poÄÃ­taÄi

Tento projekt pouÅ¾Ã­vÃ¡ modernÃ­ sprÃ¡vce balÃ­ÄkÅ¯ **`uv`**, kterÃ½ automaticky spravuje verzi Pythonu.

1.  **Nainstalujte `uv`** (pokud nemÃ¡te):
    ```powershell
    pip install uv
    # nebo
    curl -LsSf https://astral.sh/uv/install.sh | sh
    ```

2.  **PÅ™ejdÄ›te do sloÅ¾ky projektu:**
    ```powershell
    cd local-whisper
    ```

3.  **PÅ™ipravte prostÅ™edÃ­ (jednorÃ¡zovÄ›):**
    Tento pÅ™Ã­kaz stÃ¡hne Python a vÅ¡echny knihovny.
    ```powershell
    uv sync
    ```

---

## ğŸ® PouÅ¾itÃ­

### ZÃ¡kladnÃ­ pÅ™epis:
```powershell
uv run transcribe.py nahravka.mp3
```

### PÅ™epis vÃ­ce souborÅ¯ najednou:
```powershell
uv run transcribe.py audio1.mp3 audio2.wav video.mp4
```

### ZmÄ›na nastavenÃ­:
VÅ¡echna nastavenÃ­ (velikost modelu, jazyk, vÃ½stupnÃ­ formÃ¡ty, optimalizace) se dajÃ­ mÄ›nit v souboru **`config.json`**.
NenÃ­ potÅ™eba zasahovat do kÃ³du.

---

## âš¡ ZprovoznÄ›nÃ­ na NVIDIA GPU (RTX 30xx/40xx)

Aby `faster-whisper` bÄ›Å¾el bleskovÄ› na grafickÃ© kartÄ› (mÃ­sto pomalÃ©ho CPU), potÅ™ebuje knihovny **cuBLAS** a **cuDNN**. Ty nejsou souÄÃ¡stÃ­ Python balÃ­ÄkÅ¯ kvÅ¯li licenÄnÃ­m podmÃ­nkÃ¡m.

Pokud vÃ¡m skript pÃ­Å¡e `PouÅ¾Ã­vÃ¡m CPU`, ale mÃ¡te NVIDIA kartu:

1.  StÃ¡hnÄ›te si **cuDNN 8.x** a **cuBLAS** pro CUDA 12 (nebo 11, podle vaÅ¡Ã­ instalace driverÅ¯).
    *   *NejjednoduÅ¡Å¡Ã­ cesta:* StÃ¡hnÄ›te si DLL soubory z repozitÃ¡Å™e `purton-tech/Ctranslate2-Deps` nebo oficiÃ¡lnÃ­ho NVIDIA webu.
2.  ZkopÃ­rujte soubory **`cudnn_ops_infer64_8.dll`**, **`cublas64_11.dll`** (a dalÅ¡Ã­ zÃ¡vislosti) do sloÅ¾ky:
    *   `local-whisper/.venv/Lib/site-packages/ctranslate2`
    *   *Nebo jednoduÅ¡eji:* PÅ™idejte sloÅ¾ku s tÄ›mito DLL do systÃ©movÃ© promÄ›nnÃ© `PATH`.

---

## âš™ï¸ Konfigurace (config.json)

### ZÃ¡kladnÃ­ nastavenÃ­

| KlÃ­Ä | Hodnoty | Popis |
| :--- | :--- | :--- |
| `model_size` | `tiny`, `base`, `small`, `medium`, `large-v3`, `turbo` | Velikost modelu. `large-v3` je nejpÅ™esnÄ›jÅ¡Ã­, `medium` je zlatÃ½ stÅ™ed, `turbo` je nejrychlejÅ¡Ã­. |
| `device` | `auto`, `cuda`, `cpu` | `auto` se pokusÃ­ najÃ­t GPU samo. |
| `language` | `cs`, `en`, `sk`, ... | Jazyk pÅ™episu (ISO 639-1 kÃ³d). |
| `output_formats` | `["txt", "srt", "vtt", "json"]` | JakÃ© soubory se majÃ­ vygenerovat. |

### VÃ½konnostnÃ­ nastavenÃ­ (âš¡ DÅ®LEÅ½ITÃ‰ pro rychlost!)

| KlÃ­Ä | Hodnoty | Popis |
| :--- | :--- | :--- |
| `use_batched_inference` | `true` / `false` | **ZapnÄ›te pro 4-8x rychlejÅ¡Ã­ zpracovÃ¡nÃ­!** DoporuÄeno: `true` |
| `batch_size` | `8-32` | PoÄet paralelnÃ­ch chunk. VyÅ¡Å¡Ã­ = rychlejÅ¡Ã­, ale vÃ­ce pamÄ›ti. DoporuÄeno: `16` |
| `beam_size` | `1-10` | VyÅ¡Å¡Ã­ = kvalitnÄ›jÅ¡Ã­, ale pomalejÅ¡Ã­. DoporuÄeno: `5` |

### Kvalita pÅ™episu

| KlÃ­Ä | Hodnoty | Popis |
| :--- | :--- | :--- |
| `word_timestamps` | `true` / `false` | ÄŒasovÃ© znaÄky pro kaÅ¾dÃ© slovo (uÅ¾iteÄnÃ© pro karaoke, analÃ½zu). |
| `initial_prompt` | text | VlastnÃ­ jmÃ©na, terminologie pro zlepÅ¡enÃ­ pÅ™esnosti. NapÅ™: `"Ahoj, jmenuji se Jan NovÃ¡k a pracuji v IT."` |
| `temperature` | `[0.0, 0.2, ...]` | AutomatickÃ½ fallback pÅ™i Å¡patnÃ© kvalitÄ›. Default: `[0.0, 0.2, 0.4, 0.6, 0.8, 1.0]` |
| `vad_filter` | `true` / `false` | FiltrovÃ¡nÃ­ ticha (doporuÄeno: `true`). |
| `repetition_penalty` | `1.0-1.5` | Proti opakovÃ¡nÃ­ textu. `1.0` = vypnuto, `1.2` = mÃ­rnÃ© potlaÄenÃ­. |

### PokroÄilÃ© parametry

| KlÃ­Ä | VÃ½znam |
| :--- | :--- |
| `compression_ratio_threshold` | Detekce Å¡patnÄ› pÅ™epsanÃ½ch segmentÅ¯ (default: `2.4`) |
| `log_prob_threshold` | PrÃ¡h pravdÄ›podobnosti pro zamÃ­tnutÃ­ segmentu (default: `-1.0`) |
| `no_speech_threshold` | PrÃ¡h pro detekci "Å¾Ã¡dnÃ¡ Å™eÄ" (default: `0.6`) |
| `condition_on_previous_text` | Kontext z pÅ™edchozÃ­ch segmentÅ¯ (default: `true`) |

---

## ğŸ“‚ Struktura sloÅ¾ek

```
local-whisper/
â”œâ”€â”€ transcribe.py          # HlavnÃ­ pÅ™episovÃ½ skript
â”œâ”€â”€ benchmark.py           # Performance testing
â”œâ”€â”€ config.json            # VaÅ¡e konfigurace
â”œâ”€â”€ config.examples.json   # HotovÃ© pÅ™Ã­klady
â”œâ”€â”€ pyproject.toml         # Python dependencies (uv)
â”œâ”€â”€ README.md              # Tato dokumentace
â”œâ”€â”€ CODE_REVIEW.md         # TechnickÃ© detaily
â”œâ”€â”€ CHANGELOG.md           # Historie zmÄ›n
â”œâ”€â”€ LICENSE                # MIT License
â”œâ”€â”€ models/                # AI modely (auto-download)
â””â”€â”€ transcriptions/        # VÃ½stupnÃ­ pÅ™episy
```

---

## ğŸ†• HlavnÃ­ funkce

âœ… **BatchedInferencePipeline** - AÅ¾ 8x rychlejÅ¡Ã­ zpracovÃ¡nÃ­  
âœ… **Word-level timestamps** - Pro karaoke a detailnÃ­ analÃ½zu  
âœ… **Initial prompt** - ZlepÅ¡enÃ­ pÅ™esnosti pro vlastnÃ­ jmÃ©na a terminologii  
âœ… **Temperature fallback** - AutomatickÃ¡ oprava pÅ™i Å¡patnÃ©m zvuku  
âœ… **Repetition control** - Prevence opakovÃ¡nÃ­ textu  
âœ… **Multi-file support** - ZpracovÃ¡nÃ­ vÃ­ce souborÅ¯ najednou  
âœ… **Progress bar** - VizuÃ¡lnÃ­ zpÄ›tnÃ¡ vazba pÅ™i dlouhÃ½ch pÅ™episech  
âœ… **Smart error handling** - DetailnÃ­ chybovÃ© hlÃ¡Å¡ky s tipy na Å™eÅ¡enÃ­

---

## ğŸ’¡ Tipy pro maximÃ¡lnÃ­ vÃ½kon

### Pro RTX 4070:
```json
{
  "model_size": "large-v3",
  "use_batched_inference": true,
  "batch_size": 24,
  "compute_type": "float16"
}
```

### Pro CPU (kdyÅ¾ GPU nenÃ­ k dispozici):
```json
{
  "model_size": "medium",
  "use_batched_inference": false,
  "compute_type": "int8"
}
```

### Pro nejlepÅ¡Ã­ kvalitu (pomalejÅ¡Ã­):
```json
{
  "model_size": "large-v3",
  "beam_size": 10,
  "word_timestamps": true,
  "initial_prompt": "Text s vlastnÃ­mi jmÃ©ny, kterÃ¡ se vyskytujÃ­ v nahrÃ¡vce..."
}
```

---

## ğŸ› Troubleshooting

### "PouÅ¾Ã­vÃ¡m CPU" i kdyÅ¾ mÃ¡m NVIDIA kartu
â¡ï¸ Viz sekce "ZprovoznÄ›nÃ­ na NVIDIA GPU" vÃ½Å¡e.

### "Out of memory" chyba
â¡ï¸ SniÅ¾te `batch_size` v config.json (napÅ™. z 24 na 16 nebo 8).

### Å patnÃ¡ kvalita pÅ™episu
â¡ï¸ 1. ZvyÅ¡te `beam_size` na 8-10  
â¡ï¸ 2. PouÅ¾ijte `initial_prompt` s kontextem  
â¡ï¸ 3. Zkontrolujte, zda mÃ¡te sprÃ¡vnÃ½ `language` nastavenÃ½

### PÅ™epis obsahuje opakujÃ­cÃ­ se text
â¡ï¸ Nastavte `repetition_penalty: 1.2` a `no_repeat_ngram_size: 3`

---

## ğŸ“– DalÅ¡Ã­ dokumentace

- **[CODE_REVIEW.md](CODE_REVIEW.md)** - TechnickÃ¡ analÃ½za a best practices
- **[CHANGELOG.md](CHANGELOG.md)** - Historie zmÄ›n a release notes
- **[config.examples.json](config.examples.json)** - HotovÃ© pÅ™Ã­klady konfiguracÃ­
- **[benchmark.py](benchmark.py)** - Performance testing nÃ¡stroj

---

## ğŸ“„ Licence

Tento projekt je licencovÃ¡n pod [MIT License](LICENSE).

---

## ğŸ™ PodÄ›kovÃ¡nÃ­

- [SYSTRAN/faster-whisper](https://github.com/SYSTRAN/faster-whisper) - OptimalizovanÃ½ Whisper engine
- [OpenAI Whisper](https://github.com/openai/whisper) - PÅ¯vodnÃ­ AI model
- [CTranslate2](https://github.com/OpenNMT/CTranslate2) - RychlÃ¡ inference knihovna

---

## â­ PodpoÅ™te projekt

Pokud se vÃ¡m projekt lÃ­bÃ­, dejte mu hvÄ›zdiÄku na GitHubu! â­

---

<div align="center">
Made with â¤ï¸ for lokÃ¡lnÃ­, soukromÃ© a rychlÃ© pÅ™episy Å™eÄi
</div>
